{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist.ipynb",
      "provenance": [],
      "private_outputs": true,
      "mount_file_id": "12nrpN6v5JrQgIkXDNPbV7E9G97d69_Tx",
      "authorship_tag": "ABX9TyP0JtGS8RxJeCpgyeVKSB4m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Temi111/mnist/blob/master/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrOIeeFpEgfP"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D,MaxPooling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GbM4atTEia1"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train, y_train) ,(x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmM37qZbsAUy"
      },
      "source": [
        "# printing the number of samples in x_train, x_test, y_train, y_test\n",
        "print(\"Initial shape or dimensions of x_train\", str(x_train.shape))\n",
        "\n",
        "print (\"Number of samples in our training data: \" + str(len(x_train)))\n",
        "print (\"Number of labels in our training data: \" + str(len(y_train)))\n",
        "print (\"Number of samples in our test data: \" + str(len(x_test)))\n",
        "print (\"Number of labels in our test data: \" + str(len(y_test)))\n",
        "print()\n",
        "print (\"Dimensions of x_train:\" + str(x_train[0].shape))\n",
        "print (\"Labels in x_train:\" + str(y_train.shape))\n",
        "print()\n",
        "print (\"Dimensions of x_test:\" + str(x_test[0].shape))\n",
        "print (\"Labels in y_test:\" + str(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8JU1HxquH1X"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw3be87BuHx3"
      },
      "source": [
        "# importing matplot lib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plots 6 images, note subplot's arugments are nrows,ncols,index\n",
        "# we set the color map to grey since our image dataset is grayscale\n",
        "plt.subplot(331)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(332)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(333)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(334)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(335)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(336)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(337)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(338)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplot(339)\n",
        "random_num = np.random.randint(0,len(x_train))\n",
        "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "# Display out plots\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttGWnNyFuHvq"
      },
      "source": [
        "img_col = x_train[3].shape[0]\n",
        "img_row = x_train[3].shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTDwmtIbuHt2"
      },
      "source": [
        "# Getting our date in the right 'shape' needed for Keras\n",
        "# We need to add a 4th dimenion to our date thereby changing our\n",
        "# Our original image shape of (60000,28,28) to (60000,28,28,1)\n",
        "x_train=x_train.reshape(x_train.shape[0],img_col,img_row,1)\n",
        "x_test=x_test.reshape(x_test.shape[0],img_col,img_row,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyXoR02WuHps"
      },
      "source": [
        "print(\"Reshaped dimensions of x_train\", str(x_train.shape))\n",
        "print(\"Reshaped dimensions of x_test\", str(x_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCnRLDgIuHnI"
      },
      "source": [
        "\n",
        "input_shape = (x_test.shape[1:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDxItV84uHjn"
      },
      "source": [
        "input_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki9T-cQeuHh1"
      },
      "source": [
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGkMFcI6uHec"
      },
      "source": [
        "x_train/=255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHjJyZE_uHbD"
      },
      "source": [
        "x_test/=255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKNXmwo1uHZG"
      },
      "source": [
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucvved4ouHVo"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "# Now we one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "# Let's count the number columns in our hot encoded matrix \n",
        "print (\"Number of Classes: \" + str(y_test.shape[1]))\n",
        "\n",
        "num_classes = y_test.shape[1]\n",
        "num_pixels = x_train.shape[1] * x_train.shape[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB3uO8XiuHQF"
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.optimizers import SGD "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYaWs6DeEo5S"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3,3), \n",
        "                      activation='relu',\n",
        "                      input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKEX7K9ciioY"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = SGD(0.01),\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ImnQzVCisTn"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLl8dRnw43iS"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    batch_size = batch_size,\n",
        "                    epochs = epochs,\n",
        "                    verbose = 1,\n",
        "                    validation_data = (x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsthP8g3F8jX"
      },
      "source": [
        "history_dict = history.history\n",
        "\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "line1 = plt.plot(epochs, val_loss_values, label='Validation/Test Loss')\n",
        "line2 = plt.plot(epochs, loss_values, label='Training Loss')\n",
        "plt.setp(line1, linewidth=2.0, marker = '+', markersize=10.0)\n",
        "plt.setp(line2, linewidth=2.0, marker = '4', markersize=10.0)\n",
        "plt.xlabel('Epochs') \n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG4nPa2E5OGa"
      },
      "source": [
        "history_dict = history.history\n",
        "\n",
        "acc_values = history_dict['accuracy']\n",
        "val_acc_values = history_dict['val_accuracy']\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "line1 = plt.plot(epochs, val_acc_values, label='Validation/Test Accuracy')\n",
        "line2 = plt.plot(epochs, acc_values, label='Training Accuracy')\n",
        "plt.setp(line1, linewidth=2.0, marker = '+', markersize=10.0)\n",
        "plt.setp(line2, linewidth=2.0, marker = '4', markersize=10.0)\n",
        "plt.xlabel('Epochs') \n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fau0RfM2OglH"
      },
      "source": [
        "model.save(\"8_mnist_simple_cnn_10_Epochs.h5\")\n",
        "print(\"Model Saved\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxEVvVRNRQxz"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "classifier = load_model('8_mnist_simple_cnn_10_Epochs.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLj1TbDrkRGL"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ1dTSllRP1_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}